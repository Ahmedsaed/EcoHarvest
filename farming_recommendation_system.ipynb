{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 19:22:54.027676: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-05 19:22:54.027718: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-05 19:22:54.028832: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-05 19:22:55.136337: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building The Environment\n",
    "- Random temperature \n",
    "- Ideal Temp. is 37-39  \n",
    "\n",
    "Goal: Build an agent to optimize the shower temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FarmEnv(Env):\n",
    "    def __init__(self):\n",
    "        # Actions we can take, change temperature, pH, and water individually\n",
    "        self.action_space = Box(low=np.array([-1, -0.5, -5]), high=np.array([1, 0.5, 5]))\n",
    "        # Observation space (temperature, pH, water)\n",
    "        self.observation_space = Box(low=np.array([0, 0, 0]), high=np.array([100, 14, 100]))\n",
    "        # Set start values\n",
    "        self.state = np.array([38 + random.randint(-3, 3), 7 + random.uniform(-0.5, 0.5), 50 + random.uniform(-10, 10)])\n",
    "        # Set day length\n",
    "        self.day_length = 60\n",
    "\n",
    "    def step(self, action):\n",
    "        # Clip action values to be within action space\n",
    "        action = np.clip(action, self.action_space.low, self.action_space.high)\n",
    "\n",
    "        # Apply action\n",
    "        self.state += action\n",
    "\n",
    "        # Clip values to be within observation space\n",
    "        self.state = np.clip(self.state, self.observation_space.low, self.observation_space.high)\n",
    "\n",
    "        # Reduce length by 1 second\n",
    "        self.day_length -= 1\n",
    "\n",
    "        # Calculate reward\n",
    "        temp_reward = 1 if 37 <= self.state[0] <= 39 else -1\n",
    "        ph_reward = 1 if 6.5 <= self.state[1] <= 7.5 else -1\n",
    "        water_reward = 1 if 45 <= self.state[2] <= 55 else -1\n",
    "        reward = temp_reward + ph_reward + water_reward\n",
    "\n",
    "        # Check if day is done\n",
    "        done = self.day_length <= 0\n",
    "\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "\n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset farm values\n",
    "        self.state = np.array([38 + random.randint(-3, 3), 7 + random.uniform(-0.5, 0.5), 50 + random.uniform(-10, 10)])\n",
    "        # Reset day time\n",
    "        self.day_length = 60\n",
    "        return self.state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/Downloads/SIC Hackathon/ml-env/lib64/python3.11/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "env = FarmEnv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-164\n",
      "Episode:2 Score:-144\n",
      "Episode:3 Score:-132\n",
      "Episode:4 Score:-84\n",
      "Episode:5 Score:-76\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/Downloads/SIC Hackathon/ml-env/lib64/python3.11/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training', 'Logs')\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)\n",
    "save_path = os.path.join('Training', 'Saved Models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/PPO_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/Downloads/SIC Hackathon/ml-env/lib64/python3.11/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60       |\n",
      "|    ep_rew_mean     | -88      |\n",
      "| time/              |          |\n",
      "|    fps             | 1468     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -81.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 951         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007835183 |\n",
      "|    clip_fraction        | 0.0788      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.26       |\n",
      "|    explained_variance   | -0.0019     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00916    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 388         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -71.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 843          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073731877 |\n",
      "|    clip_fraction        | 0.065        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.25        |\n",
      "|    explained_variance   | -4.91e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 165          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    std                  | 0.989        |\n",
      "|    value_loss           | 288          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -58.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 784         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012223996 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.24       |\n",
      "|    explained_variance   | 3.1e-06     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 207         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=7.20 +/- 96.68\n",
      "Episode length: 60.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 60           |\n",
      "|    mean_reward          | 7.2          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067349277 |\n",
      "|    clip_fraction        | 0.0925       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.23        |\n",
      "|    explained_variance   | -5.6e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 109          |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00579     |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 240          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/Downloads/SIC Hackathon/ml-env/lib64/python3.11/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | -52.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 746      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | -52.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 735          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033320626 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.2         |\n",
      "|    explained_variance   | 4.24e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 147          |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    std                  | 0.981        |\n",
      "|    value_loss           | 267          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | -52.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 722          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031597086 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.19        |\n",
      "|    explained_variance   | 0.00199      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 113          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    std                  | 0.978        |\n",
      "|    value_loss           | 246          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -50.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 714          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041876724 |\n",
      "|    clip_fraction        | 0.0324       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.19        |\n",
      "|    explained_variance   | 0.00799      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 132          |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    std                  | 0.976        |\n",
      "|    value_loss           | 251          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -47.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 709         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005228628 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | -0.000838   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    std                  | 0.975       |\n",
      "|    value_loss           | 278         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-72.40 +/- 80.65\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | -72.4       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006107906 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | -0.000713   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 90.4        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    std                  | 0.975       |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | -42.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 703      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | -42         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 704         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008186926 |\n",
      "|    clip_fraction        | 0.0515      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | -0.00111    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 234         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | -46.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002564688 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.0017      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.000845   |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 253         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -47.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008178358 |\n",
      "|    clip_fraction        | 0.0487      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.00149     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 248         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -41.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 700          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071919933 |\n",
      "|    clip_fraction        | 0.0814       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.18        |\n",
      "|    explained_variance   | -0.00247     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 137          |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    std                  | 0.976        |\n",
      "|    value_loss           | 270          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=32.80 +/- 66.11\n",
      "Episode length: 60.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 60           |\n",
      "|    mean_reward          | 32.8         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 30000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058371373 |\n",
      "|    clip_fraction        | 0.0606       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.18        |\n",
      "|    explained_variance   | -0.0125      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 141          |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00652     |\n",
      "|    std                  | 0.975        |\n",
      "|    value_loss           | 259          |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | -29.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 698      |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 43       |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | -26.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 700          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049242107 |\n",
      "|    clip_fraction        | 0.0562       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.18        |\n",
      "|    explained_variance   | -0.00186     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 71.5         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    std                  | 0.972        |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | -32.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009664176 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | -0.00831    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    std                  | 0.963       |\n",
      "|    value_loss           | 328         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -37.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004182172 |\n",
      "|    clip_fraction        | 0.0546      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | -8.94e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.000494    |\n",
      "|    std                  | 0.96        |\n",
      "|    value_loss           | 242         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -34.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 704          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071980804 |\n",
      "|    clip_fraction        | 0.0784       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.13        |\n",
      "|    explained_variance   | 0.00793      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 114          |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00537     |\n",
      "|    std                  | 0.956        |\n",
      "|    value_loss           | 210          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=88.80 +/- 57.39\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 88.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007321177 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.12       |\n",
      "|    explained_variance   | -0.000836   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.000725   |\n",
      "|    std                  | 0.955       |\n",
      "|    value_loss           | 276         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | -29.9    |\n",
      "| time/              |          |\n",
      "|    fps             | 703      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | -27.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 704          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064861863 |\n",
      "|    clip_fraction        | 0.0896       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.11        |\n",
      "|    explained_variance   | 0.00236      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 93           |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00756     |\n",
      "|    std                  | 0.953        |\n",
      "|    value_loss           | 234          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | -26.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 705          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075403834 |\n",
      "|    clip_fraction        | 0.0582       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.11        |\n",
      "|    explained_variance   | -0.00622     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 109          |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    std                  | 0.949        |\n",
      "|    value_loss           | 248          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -23          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 705          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049030706 |\n",
      "|    clip_fraction        | 0.0557       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.1         |\n",
      "|    explained_variance   | -0.00266     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 94.9         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.000725    |\n",
      "|    std                  | 0.947        |\n",
      "|    value_loss           | 200          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -15         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 700         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011224913 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.09       |\n",
      "|    explained_variance   | -0.0122     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 79.7        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    std                  | 0.946       |\n",
      "|    value_loss           | 225         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=96.40 +/- 63.60\n",
      "Episode length: 60.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 60           |\n",
      "|    mean_reward          | 96.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 50000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086657945 |\n",
      "|    clip_fraction        | 0.0952       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.09        |\n",
      "|    explained_variance   | 0.000713     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 64.2         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    std                  | 0.944        |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | -15.9    |\n",
      "| time/              |          |\n",
      "|    fps             | 698      |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 73       |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | -17         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 696         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004098966 |\n",
      "|    clip_fraction        | 0.0495      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.08       |\n",
      "|    explained_variance   | 0.0158      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.000323    |\n",
      "|    std                  | 0.942       |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | -20.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071651824 |\n",
      "|    clip_fraction        | 0.0658       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.07        |\n",
      "|    explained_variance   | 0.0321       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 81.8         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    std                  | 0.939        |\n",
      "|    value_loss           | 233          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -18.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 694         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011021126 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.06       |\n",
      "|    explained_variance   | 0.0017      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    std                  | 0.937       |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -14.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 693         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007182286 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.06       |\n",
      "|    explained_variance   | 0.017       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 179         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    std                  | 0.934       |\n",
      "|    value_loss           | 276         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=79.60 +/- 84.27\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 79.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004461305 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.04       |\n",
      "|    explained_variance   | -0.0242     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    std                  | 0.929       |\n",
      "|    value_loss           | 254         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | -16.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 693      |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 88       |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | -15.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 692         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005191547 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.03       |\n",
      "|    explained_variance   | 0.00576     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.000648   |\n",
      "|    std                  | 0.924       |\n",
      "|    value_loss           | 248         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | -9.62      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 692        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 94         |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02011062 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4         |\n",
      "|    explained_variance   | -0.0222    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 135        |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | 0.00258    |\n",
      "|    std                  | 0.913      |\n",
      "|    value_loss           | 259        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -4.74       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010243399 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 0.01        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    std                  | 0.912       |\n",
      "|    value_loss           | 223         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -5.64       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 692         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010889766 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.97       |\n",
      "|    explained_variance   | -0.00868    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | 0.000793    |\n",
      "|    std                  | 0.909       |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=55.60 +/- 73.60\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 55.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007855848 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.95       |\n",
      "|    explained_variance   | -0.0477     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | 0.00503     |\n",
      "|    std                  | 0.898       |\n",
      "|    value_loss           | 279         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | -5.52    |\n",
      "| time/              |          |\n",
      "|    fps             | 691      |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 103      |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | -10.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009699099 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.91       |\n",
      "|    explained_variance   | -0.00269    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.000359   |\n",
      "|    std                  | 0.888       |\n",
      "|    value_loss           | 251         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | -7.96       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008952607 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.89       |\n",
      "|    explained_variance   | 0.00176     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | 0.00144     |\n",
      "|    std                  | 0.884       |\n",
      "|    value_loss           | 308         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -2.76       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 686         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008546029 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.89       |\n",
      "|    explained_variance   | -0.00761    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | 0.00172     |\n",
      "|    std                  | 0.884       |\n",
      "|    value_loss           | 285         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 5.78        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009708586 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.88       |\n",
      "|    explained_variance   | -0.0139     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.7        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | 0.000829    |\n",
      "|    std                  | 0.882       |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=94.80 +/- 47.02\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 94.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022763874 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.89       |\n",
      "|    explained_variance   | -0.0172     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.00545     |\n",
      "|    std                  | 0.886       |\n",
      "|    value_loss           | 277         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 8.32     |\n",
      "| time/              |          |\n",
      "|    fps             | 686      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 119      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 0.86        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022637691 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.89       |\n",
      "|    explained_variance   | -4.21e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | 0.00201     |\n",
      "|    std                  | 0.886       |\n",
      "|    value_loss           | 313         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | -4.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009930186 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.9        |\n",
      "|    explained_variance   | 0.00192     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 0.00127     |\n",
      "|    std                  | 0.888       |\n",
      "|    value_loss           | 230         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 2.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010289222 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.88       |\n",
      "|    explained_variance   | 0.00278     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    std                  | 0.878       |\n",
      "|    value_loss           | 242         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=80.00 +/- 33.44\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 80          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015593252 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.87       |\n",
      "|    explained_variance   | -0.00576    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.00163     |\n",
      "|    std                  | 0.884       |\n",
      "|    value_loss           | 217         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 10.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 682      |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 132      |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 17.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 682        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 135        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01249923 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.87      |\n",
      "|    explained_variance   | -0.00111   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 60.4       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | 0.00113    |\n",
      "|    std                  | 0.875      |\n",
      "|    value_loss           | 174        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 16.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009544306 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.84       |\n",
      "|    explained_variance   | -9.45e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.1        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | 0.00211     |\n",
      "|    std                  | 0.868       |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 19.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 680         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014050756 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.83       |\n",
      "|    explained_variance   | 0.000475    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 149         |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    std                  | 0.867       |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 21.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 681         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014336649 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.00385     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 89          |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.000488   |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 209         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=72.00 +/- 49.33\n",
      "Episode length: 60.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 60           |\n",
      "|    mean_reward          | 72           |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 100000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0112650525 |\n",
      "|    clip_fraction        | 0.17         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.8         |\n",
      "|    explained_variance   | -0.00119     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 80.9         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | 0.00355      |\n",
      "|    std                  | 0.855        |\n",
      "|    value_loss           | 171          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 29.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 680      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 147      |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 23.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 681         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010659023 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.77       |\n",
      "|    explained_variance   | 0.00102     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 81.4        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | 0.000788    |\n",
      "|    std                  | 0.847       |\n",
      "|    value_loss           | 230         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 26.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 681         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008161718 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.76       |\n",
      "|    explained_variance   | -0.000585   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 98.3        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    std                  | 0.849       |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 28.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 681         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011531644 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | -0.0195     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 85.8        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | 0.00526     |\n",
      "|    std                  | 0.83        |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | 37.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 682        |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 159        |\n",
      "|    total_timesteps      | 108544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01827912 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.68      |\n",
      "|    explained_variance   | -6.27e-05  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 182        |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | -0.00563   |\n",
      "|    std                  | 0.824      |\n",
      "|    value_loss           | 288        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=78.40 +/- 32.95\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 78.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 110000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020420365 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.66       |\n",
      "|    explained_variance   | 1.94e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | 0.00174     |\n",
      "|    std                  | 0.815       |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 35.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 682      |\n",
      "|    iterations      | 54       |\n",
      "|    time_elapsed    | 161      |\n",
      "|    total_timesteps | 110592   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 33.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015758885 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.64       |\n",
      "|    explained_variance   | -0.00254    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 87.1        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00192    |\n",
      "|    std                  | 0.813       |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 31.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020957876 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | 0.000997    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    std                  | 0.807       |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 36.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 170         |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015493307 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.61       |\n",
      "|    explained_variance   | 0.00391     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.1        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    std                  | 0.803       |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 46.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014045804 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.00528     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    std                  | 0.803       |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=100.00 +/- 36.90\n",
      "Episode length: 60.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 60         |\n",
      "|    mean_reward          | 100        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 120000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01535999 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.58      |\n",
      "|    explained_variance   | -0.00234   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 91.9       |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | 0.00628    |\n",
      "|    std                  | 0.793      |\n",
      "|    value_loss           | 203        |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 54.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 685      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 176      |\n",
      "|    total_timesteps | 120832   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 59.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 685        |\n",
      "|    iterations           | 60         |\n",
      "|    time_elapsed         | 179        |\n",
      "|    total_timesteps      | 122880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01567162 |\n",
      "|    clip_fraction        | 0.264      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.55      |\n",
      "|    explained_variance   | 6.25e-05   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 135        |\n",
      "|    n_updates            | 590        |\n",
      "|    policy_gradient_loss | 0.00441    |\n",
      "|    std                  | 0.791      |\n",
      "|    value_loss           | 278        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 57.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 686         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018003764 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.55       |\n",
      "|    explained_variance   | 0.000708    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | 0.00566     |\n",
      "|    std                  | 0.789       |\n",
      "|    value_loss           | 261         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 61.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 185         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013061693 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.55       |\n",
      "|    explained_variance   | -0.000568   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 74.6        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | 0.00976     |\n",
      "|    std                  | 0.791       |\n",
      "|    value_loss           | 200         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 64.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011360008 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | -0.00031    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.00801     |\n",
      "|    std                  | 0.783       |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=145.20 +/- 28.44\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 145         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 130000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020371046 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 9.88e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | 0.00148     |\n",
      "|    std                  | 0.779       |\n",
      "|    value_loss           | 248         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 63       |\n",
      "| time/              |          |\n",
      "|    fps             | 685      |\n",
      "|    iterations      | 64       |\n",
      "|    time_elapsed    | 191      |\n",
      "|    total_timesteps | 131072   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 61.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013895581 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.000195    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.000954   |\n",
      "|    std                  | 0.776       |\n",
      "|    value_loss           | 250         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 60.4      |\n",
      "|    ep_rew_mean          | 63.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 685       |\n",
      "|    iterations           | 66        |\n",
      "|    time_elapsed         | 197       |\n",
      "|    total_timesteps      | 135168    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0260446 |\n",
      "|    clip_fraction        | 0.25      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.48     |\n",
      "|    explained_variance   | -0.000803 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 115       |\n",
      "|    n_updates            | 650       |\n",
      "|    policy_gradient_loss | 0.00226   |\n",
      "|    std                  | 0.772     |\n",
      "|    value_loss           | 208       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | 62.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 682        |\n",
      "|    iterations           | 67         |\n",
      "|    time_elapsed         | 201        |\n",
      "|    total_timesteps      | 137216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02719904 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.47      |\n",
      "|    explained_variance   | 0.000207   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 111        |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | 0.00592    |\n",
      "|    std                  | 0.768      |\n",
      "|    value_loss           | 242        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 62.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 680         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011749579 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.000135    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    std                  | 0.764       |\n",
      "|    value_loss           | 292         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=153.20 +/- 16.81\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 153         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 140000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011293581 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.44       |\n",
      "|    explained_variance   | 0.00706     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | 0.00378     |\n",
      "|    std                  | 0.759       |\n",
      "|    value_loss           | 216         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 64.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 679      |\n",
      "|    iterations      | 69       |\n",
      "|    time_elapsed    | 207      |\n",
      "|    total_timesteps | 141312   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 71.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 676         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010505991 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.44       |\n",
      "|    explained_variance   | 0.00506     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | 0.0101      |\n",
      "|    std                  | 0.763       |\n",
      "|    value_loss           | 260         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 78.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 673        |\n",
      "|    iterations           | 71         |\n",
      "|    time_elapsed         | 215        |\n",
      "|    total_timesteps      | 145408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01820729 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.41      |\n",
      "|    explained_variance   | -0.00107   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 119        |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | 0.00424    |\n",
      "|    std                  | 0.751      |\n",
      "|    value_loss           | 246        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 63.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 671         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019718394 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.38       |\n",
      "|    explained_variance   | 2.69e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | 0.0116      |\n",
      "|    std                  | 0.747       |\n",
      "|    value_loss           | 262         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 60.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 670         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011265154 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 8.24e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 202         |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 0.746       |\n",
      "|    value_loss           | 399         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=166.00 +/- 11.31\n",
      "Episode length: 60.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 60         |\n",
      "|    mean_reward          | 166        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 150000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01007853 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.37      |\n",
      "|    explained_variance   | 0.0273     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 103        |\n",
      "|    n_updates            | 730        |\n",
      "|    policy_gradient_loss | -0.00851   |\n",
      "|    std                  | 0.745      |\n",
      "|    value_loss           | 233        |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 61.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 667      |\n",
      "|    iterations      | 74       |\n",
      "|    time_elapsed    | 227      |\n",
      "|    total_timesteps | 151552   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 60.4      |\n",
      "|    ep_rew_mean          | 78.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 665       |\n",
      "|    iterations           | 75        |\n",
      "|    time_elapsed         | 230       |\n",
      "|    total_timesteps      | 153600    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0320907 |\n",
      "|    clip_fraction        | 0.267     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.36     |\n",
      "|    explained_variance   | 0.00997   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 122       |\n",
      "|    n_updates            | 740       |\n",
      "|    policy_gradient_loss | 0.0147    |\n",
      "|    std                  | 0.743     |\n",
      "|    value_loss           | 255       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 78.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 664         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020471638 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.33       |\n",
      "|    explained_variance   | -0.000292   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | 0.0101      |\n",
      "|    std                  | 0.731       |\n",
      "|    value_loss           | 254         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 76.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 662         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014150367 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | -0.000151   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 170         |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | 0.00235     |\n",
      "|    std                  | 0.731       |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 71.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 660         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 241         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014904632 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | -1.42e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | 0.00985     |\n",
      "|    std                  | 0.733       |\n",
      "|    value_loss           | 265         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=163.60 +/- 13.76\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 164         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019342434 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.3        |\n",
      "|    explained_variance   | -3.22e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 149         |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | 0.000547    |\n",
      "|    std                  | 0.729       |\n",
      "|    value_loss           | 289         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 72       |\n",
      "| time/              |          |\n",
      "|    fps             | 658      |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 245      |\n",
      "|    total_timesteps | 161792   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 76.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 656        |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 249        |\n",
      "|    total_timesteps      | 163840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02349329 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.3       |\n",
      "|    explained_variance   | -2.74e-05  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 117        |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | 0.00445    |\n",
      "|    std                  | 0.731      |\n",
      "|    value_loss           | 249        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 87.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 655         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013035061 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 2.44e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 149         |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | 0.00994     |\n",
      "|    std                  | 0.722       |\n",
      "|    value_loss           | 283         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 89.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 256         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014303284 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | -2.74e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 198         |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | 0.00493     |\n",
      "|    std                  | 0.721       |\n",
      "|    value_loss           | 307         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | 86.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 654        |\n",
      "|    iterations           | 83         |\n",
      "|    time_elapsed         | 259        |\n",
      "|    total_timesteps      | 169984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01211928 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.26      |\n",
      "|    explained_variance   | 6.5e-06    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 202        |\n",
      "|    n_updates            | 820        |\n",
      "|    policy_gradient_loss | 0.00838    |\n",
      "|    std                  | 0.72       |\n",
      "|    value_loss           | 319        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=164.80 +/- 19.12\n",
      "Episode length: 60.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 60        |\n",
      "|    mean_reward          | 165       |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 170000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0209141 |\n",
      "|    clip_fraction        | 0.236     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.25     |\n",
      "|    explained_variance   | 6.26e-06  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 158       |\n",
      "|    n_updates            | 830       |\n",
      "|    policy_gradient_loss | 0.00446   |\n",
      "|    std                  | 0.718     |\n",
      "|    value_loss           | 331       |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 86.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 652      |\n",
      "|    iterations      | 84       |\n",
      "|    time_elapsed    | 263      |\n",
      "|    total_timesteps | 172032   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 88.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016708914 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.24       |\n",
      "|    explained_variance   | 1.49e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 206         |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | 0.00997     |\n",
      "|    std                  | 0.715       |\n",
      "|    value_loss           | 310         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 90          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019055825 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | 5.36e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 178         |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | 0.00887     |\n",
      "|    std                  | 0.713       |\n",
      "|    value_loss           | 329         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 90.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 651         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 273         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040111877 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | -9.54e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 200         |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | 0.0141      |\n",
      "|    std                  | 0.712       |\n",
      "|    value_loss           | 340         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=168.80 +/- 8.63\n",
      "Episode length: 60.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 60         |\n",
      "|    mean_reward          | 169        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 180000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02464517 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.22      |\n",
      "|    explained_variance   | 1.79e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 150        |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | 0.0108     |\n",
      "|    std                  | 0.713      |\n",
      "|    value_loss           | 347        |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 92.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 650      |\n",
      "|    iterations      | 88       |\n",
      "|    time_elapsed    | 277      |\n",
      "|    total_timesteps | 180224   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 90.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 280         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024218787 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.22       |\n",
      "|    explained_variance   | -1.55e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 219         |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | 0.0118      |\n",
      "|    std                  | 0.711       |\n",
      "|    value_loss           | 356         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 86.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 283         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020729732 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.22       |\n",
      "|    explained_variance   | 1.85e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | 0.00522     |\n",
      "|    std                  | 0.712       |\n",
      "|    value_loss           | 343         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 84.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015688326 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | 5.54e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 163         |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | 0.00321     |\n",
      "|    std                  | 0.708       |\n",
      "|    value_loss           | 351         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | 88.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 649        |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 290        |\n",
      "|    total_timesteps      | 188416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01818627 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.2       |\n",
      "|    explained_variance   | 0.00537    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 169        |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | 0.00104    |\n",
      "|    std                  | 0.707      |\n",
      "|    value_loss           | 333        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=68.40 +/- 16.94\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 68.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 190000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013296249 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.2        |\n",
      "|    explained_variance   | 0.00313     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | 0.0119      |\n",
      "|    std                  | 0.705       |\n",
      "|    value_loss           | 337         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 94.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 648      |\n",
      "|    iterations      | 93       |\n",
      "|    time_elapsed    | 293      |\n",
      "|    total_timesteps | 190464   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 93.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 647         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 297         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007020862 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.000902    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 159         |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | 0.00888     |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 347         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 93.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 647        |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 300        |\n",
      "|    total_timesteps      | 194560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01643201 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.15      |\n",
      "|    explained_variance   | 0.00609    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 166        |\n",
      "|    n_updates            | 940        |\n",
      "|    policy_gradient_loss | -0.00593   |\n",
      "|    std                  | 0.695      |\n",
      "|    value_loss           | 363        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 93.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 304         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009230156 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.00921     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 165         |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | 0.00272     |\n",
      "|    std                  | 0.693       |\n",
      "|    value_loss           | 347         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 91.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012492498 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.00323     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 196         |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | 0.0117      |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 362         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=170.80 +/- 6.27\n",
      "Episode length: 60.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 60           |\n",
      "|    mean_reward          | 171          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 200000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072037317 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.15        |\n",
      "|    explained_variance   | 0.0115       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 230          |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    std                  | 0.693        |\n",
      "|    value_loss           | 376          |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 88.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 646      |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 310      |\n",
      "|    total_timesteps | 200704   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 87.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 313         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010017244 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | -0.00206    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 158         |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | 0.00611     |\n",
      "|    std                  | 0.692       |\n",
      "|    value_loss           | 312         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 85.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010432791 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.0146      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | 0.00111     |\n",
      "|    std                  | 0.692       |\n",
      "|    value_loss           | 320         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 82.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008049449 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.0376      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 162         |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    std                  | 0.693       |\n",
      "|    value_loss           | 337         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 80.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 646          |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 323          |\n",
      "|    total_timesteps      | 208896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072294283 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.14        |\n",
      "|    explained_variance   | 0.0562       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 109          |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    std                  | 0.692        |\n",
      "|    value_loss           | 297          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=76.40 +/- 10.98\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 76.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 210000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012167423 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.13       |\n",
      "|    explained_variance   | 0.0605      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    std                  | 0.691       |\n",
      "|    value_loss           | 294         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 80.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 646      |\n",
      "|    iterations      | 103      |\n",
      "|    time_elapsed    | 326      |\n",
      "|    total_timesteps | 210944   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 87.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010392072 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.13       |\n",
      "|    explained_variance   | 0.076       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 161         |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | 0.000998    |\n",
      "|    std                  | 0.69        |\n",
      "|    value_loss           | 288         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 77.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 647         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 332         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032834344 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.13       |\n",
      "|    explained_variance   | 0.0221      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 200         |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | 0.0156      |\n",
      "|    std                  | 0.689       |\n",
      "|    value_loss           | 291         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 73.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 647         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022826523 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.13       |\n",
      "|    explained_variance   | -0.0614     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 156         |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | 0.0274      |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 303         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 69.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 648         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 338         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020531656 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | 0.000486    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | 0.0228      |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 278         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=160.80 +/- 12.94\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 161         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 220000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018679395 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.000183    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | 0.0159      |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 238         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 85.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 648      |\n",
      "|    iterations      | 108      |\n",
      "|    time_elapsed    | 341      |\n",
      "|    total_timesteps | 221184   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 94.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 649        |\n",
      "|    iterations           | 109        |\n",
      "|    time_elapsed         | 343        |\n",
      "|    total_timesteps      | 223232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01620008 |\n",
      "|    clip_fraction        | 0.293      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.16      |\n",
      "|    explained_variance   | 0.00139    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 116        |\n",
      "|    n_updates            | 1080       |\n",
      "|    policy_gradient_loss | 0.0138     |\n",
      "|    std                  | 0.697      |\n",
      "|    value_loss           | 338        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 92          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 346         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017144624 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | -0.000363   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 167         |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | 0.0169      |\n",
      "|    std                  | 0.694       |\n",
      "|    value_loss           | 338         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 84.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030974612 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.14       |\n",
      "|    explained_variance   | 0.0029      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 193         |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | 0.00746     |\n",
      "|    std                  | 0.691       |\n",
      "|    value_loss           | 332         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 83.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018028796 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.00846     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | 0.00884     |\n",
      "|    std                  | 0.686       |\n",
      "|    value_loss           | 337         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=155.60 +/- 12.74\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 156         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 230000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021934137 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.11       |\n",
      "|    explained_variance   | 0.0054      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 168         |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | 0.0124      |\n",
      "|    std                  | 0.686       |\n",
      "|    value_loss           | 329         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 89.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 650      |\n",
      "|    iterations      | 113      |\n",
      "|    time_elapsed    | 355      |\n",
      "|    total_timesteps | 231424   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 94.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 358         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014945768 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.00329     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 180         |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | 0.0225      |\n",
      "|    std                  | 0.687       |\n",
      "|    value_loss           | 379         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 96.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 651         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 361         |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017800152 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.00327     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | 0.0156      |\n",
      "|    std                  | 0.688       |\n",
      "|    value_loss           | 350         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 89.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 651         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021226276 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | 0.00395     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 244         |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | 0.0122      |\n",
      "|    std                  | 0.683       |\n",
      "|    value_loss           | 391         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 91.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 651         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 367         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058885142 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.09       |\n",
      "|    explained_variance   | -0.00182    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 229         |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | 0.0136      |\n",
      "|    std                  | 0.68        |\n",
      "|    value_loss           | 379         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=155.60 +/- 16.75\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 156         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031889156 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.07       |\n",
      "|    explained_variance   | 0.00315     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 179         |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | 0.0184      |\n",
      "|    std                  | 0.674       |\n",
      "|    value_loss           | 397         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 90       |\n",
      "| time/              |          |\n",
      "|    fps             | 651      |\n",
      "|    iterations      | 118      |\n",
      "|    time_elapsed    | 370      |\n",
      "|    total_timesteps | 241664   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 90.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 652        |\n",
      "|    iterations           | 119        |\n",
      "|    time_elapsed         | 373        |\n",
      "|    total_timesteps      | 243712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02777004 |\n",
      "|    clip_fraction        | 0.407      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.04      |\n",
      "|    explained_variance   | -0.00553   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 221        |\n",
      "|    n_updates            | 1180       |\n",
      "|    policy_gradient_loss | 0.0318     |\n",
      "|    std                  | 0.666      |\n",
      "|    value_loss           | 398        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 87.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 376         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032802008 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.01       |\n",
      "|    explained_variance   | -0.000293   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | 0.0267      |\n",
      "|    std                  | 0.66        |\n",
      "|    value_loss           | 352         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 91.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 652          |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 379          |\n",
      "|    total_timesteps      | 247808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048355283 |\n",
      "|    clip_fraction        | 0.219        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3           |\n",
      "|    explained_variance   | 0.00125      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 200          |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | 0.00881      |\n",
      "|    std                  | 0.662        |\n",
      "|    value_loss           | 368          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 72.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 382         |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034900144 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.01       |\n",
      "|    explained_variance   | 0.0159      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 180         |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | 0.0139      |\n",
      "|    std                  | 0.662       |\n",
      "|    value_loss           | 387         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=158.40 +/- 15.92\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 158         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 250000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022570446 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3          |\n",
      "|    explained_variance   | -0.054      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.00196    |\n",
      "|    std                  | 0.664       |\n",
      "|    value_loss           | 304         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 71       |\n",
      "| time/              |          |\n",
      "|    fps             | 653      |\n",
      "|    iterations      | 123      |\n",
      "|    time_elapsed    | 385      |\n",
      "|    total_timesteps | 251904   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 60.4      |\n",
      "|    ep_rew_mean          | 63        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 653       |\n",
      "|    iterations           | 124       |\n",
      "|    time_elapsed         | 388       |\n",
      "|    total_timesteps      | 253952    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0855879 |\n",
      "|    clip_fraction        | 0.178     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3        |\n",
      "|    explained_variance   | -0.00835  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 109       |\n",
      "|    n_updates            | 1230      |\n",
      "|    policy_gradient_loss | 0.00555   |\n",
      "|    std                  | 0.66      |\n",
      "|    value_loss           | 261       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 80.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 653        |\n",
      "|    iterations           | 125        |\n",
      "|    time_elapsed         | 391        |\n",
      "|    total_timesteps      | 256000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03549829 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3         |\n",
      "|    explained_variance   | -0.00607   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 163        |\n",
      "|    n_updates            | 1240       |\n",
      "|    policy_gradient_loss | 0.0168     |\n",
      "|    std                  | 0.662      |\n",
      "|    value_loss           | 307        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 74.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 394         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014145817 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | 0.00302     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | 0.00391     |\n",
      "|    std                  | 0.658       |\n",
      "|    value_loss           | 290         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=70.00 +/- 28.26\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 70          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 260000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017578105 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.98       |\n",
      "|    explained_variance   | 0.00373     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    std                  | 0.655       |\n",
      "|    value_loss           | 295         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 68.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 654      |\n",
      "|    iterations      | 127      |\n",
      "|    time_elapsed    | 397      |\n",
      "|    total_timesteps | 260096   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 72.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 400         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017877135 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.0318      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | 0.00677     |\n",
      "|    std                  | 0.652       |\n",
      "|    value_loss           | 235         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 63.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023258757 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.95       |\n",
      "|    explained_variance   | 0.00585     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 95.9        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | 0.0257      |\n",
      "|    std                  | 0.65        |\n",
      "|    value_loss           | 236         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 69.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 655         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 406         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017636472 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.94       |\n",
      "|    explained_variance   | 0.0269      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | 0.018       |\n",
      "|    std                  | 0.648       |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | 60.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 655        |\n",
      "|    iterations           | 131        |\n",
      "|    time_elapsed         | 409        |\n",
      "|    total_timesteps      | 268288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06463226 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.92      |\n",
      "|    explained_variance   | 0.0186     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 129        |\n",
      "|    n_updates            | 1300       |\n",
      "|    policy_gradient_loss | 0.00311    |\n",
      "|    std                  | 0.643      |\n",
      "|    value_loss           | 263        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=72.40 +/- 32.58\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 72.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 270000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010449776 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.9        |\n",
      "|    explained_variance   | 0.053       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 173         |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | 0.000135    |\n",
      "|    std                  | 0.638       |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 67.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 655      |\n",
      "|    iterations      | 132      |\n",
      "|    time_elapsed    | 412      |\n",
      "|    total_timesteps | 270336   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 70.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 415         |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010904359 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0.0509      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 181         |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | 0.00391     |\n",
      "|    std                  | 0.638       |\n",
      "|    value_loss           | 248         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 82.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 656        |\n",
      "|    iterations           | 134        |\n",
      "|    time_elapsed         | 418        |\n",
      "|    total_timesteps      | 274432     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03202442 |\n",
      "|    clip_fraction        | 0.236      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.89      |\n",
      "|    explained_variance   | 0.0192     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 135        |\n",
      "|    n_updates            | 1330       |\n",
      "|    policy_gradient_loss | 0.00574    |\n",
      "|    std                  | 0.637      |\n",
      "|    value_loss           | 287        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 92          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 420         |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015044427 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | -0.00518    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | 0.0139      |\n",
      "|    std                  | 0.638       |\n",
      "|    value_loss           | 298         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 89          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 657         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 423         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.085908964 |\n",
      "|    clip_fraction        | 0.435       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.9        |\n",
      "|    explained_variance   | 0.000221    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 204         |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | 0.0553      |\n",
      "|    std                  | 0.643       |\n",
      "|    value_loss           | 323         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=167.60 +/- 18.08\n",
      "Episode length: 60.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 60         |\n",
      "|    mean_reward          | 168        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 280000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01710064 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.9       |\n",
      "|    explained_variance   | -0.0049    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 218        |\n",
      "|    n_updates            | 1360       |\n",
      "|    policy_gradient_loss | 0.0117     |\n",
      "|    std                  | 0.639      |\n",
      "|    value_loss           | 355        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 90.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 657      |\n",
      "|    iterations      | 137      |\n",
      "|    time_elapsed    | 426      |\n",
      "|    total_timesteps | 280576   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 68.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 657        |\n",
      "|    iterations           | 138        |\n",
      "|    time_elapsed         | 429        |\n",
      "|    total_timesteps      | 282624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04927565 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.88      |\n",
      "|    explained_variance   | -0.0004    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 217        |\n",
      "|    n_updates            | 1370       |\n",
      "|    policy_gradient_loss | 0.0146     |\n",
      "|    std                  | 0.636      |\n",
      "|    value_loss           | 370        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | 64           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 657          |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 432          |\n",
      "|    total_timesteps      | 284672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104358895 |\n",
      "|    clip_fraction        | 0.289        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | -0.00261     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 136          |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | 0.00835      |\n",
      "|    std                  | 0.633        |\n",
      "|    value_loss           | 304          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 61.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 658         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 435         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021499768 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.0924      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    std                  | 0.631       |\n",
      "|    value_loss           | 303         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 76.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 658         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 438         |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015950592 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.0442      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | 0.00228     |\n",
      "|    std                  | 0.625       |\n",
      "|    value_loss           | 276         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=166.00 +/- 16.10\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 166         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 290000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013159044 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.0663      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | 0.00573     |\n",
      "|    std                  | 0.624       |\n",
      "|    value_loss           | 284         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 84.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 658      |\n",
      "|    iterations      | 142      |\n",
      "|    time_elapsed    | 441      |\n",
      "|    total_timesteps | 290816   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.4       |\n",
      "|    ep_rew_mean          | 6.62       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 658        |\n",
      "|    iterations           | 143        |\n",
      "|    time_elapsed         | 444        |\n",
      "|    total_timesteps      | 292864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.41594112 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.83      |\n",
      "|    explained_variance   | 0.0283     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 136        |\n",
      "|    n_updates            | 1420       |\n",
      "|    policy_gradient_loss | 0.0253     |\n",
      "|    std                  | 0.624      |\n",
      "|    value_loss           | 321        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | -62.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 659         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 447         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016387507 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | 0.021       |\n",
      "|    std                  | 0.624       |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | -131         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 659          |\n",
      "|    iterations           | 145          |\n",
      "|    time_elapsed         | 450          |\n",
      "|    total_timesteps      | 296960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0152017325 |\n",
      "|    clip_fraction        | 0.386        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | -0.104       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 119          |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | 0.0346       |\n",
      "|    std                  | 0.636        |\n",
      "|    value_loss           | 240          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | -126        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 659         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 453         |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012277762 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.0156      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 197         |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | 0.00692     |\n",
      "|    std                  | 0.637       |\n",
      "|    value_loss           | 360         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=-139.20 +/- 8.91\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | -139        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 300000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015906323 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0.028       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 334         |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | 0.0172      |\n",
      "|    std                  | 0.636       |\n",
      "|    value_loss           | 480         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | -122     |\n",
      "| time/              |          |\n",
      "|    fps             | 659      |\n",
      "|    iterations      | 147      |\n",
      "|    time_elapsed    | 456      |\n",
      "|    total_timesteps | 301056   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | -104        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 660         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 459         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011697842 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.0215      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 328         |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | 0.00422     |\n",
      "|    std                  | 0.637       |\n",
      "|    value_loss           | 531         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | -76.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 660         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 462         |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009604266 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0.0026      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 290         |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    std                  | 0.637       |\n",
      "|    value_loss           | 544         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | -44.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 660        |\n",
      "|    iterations           | 150        |\n",
      "|    time_elapsed         | 464        |\n",
      "|    total_timesteps      | 307200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02994071 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.89      |\n",
      "|    explained_variance   | 0.00612    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 209        |\n",
      "|    n_updates            | 1490       |\n",
      "|    policy_gradient_loss | -0.0035    |\n",
      "|    std                  | 0.639      |\n",
      "|    value_loss           | 412        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | -22.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 660        |\n",
      "|    iterations           | 151        |\n",
      "|    time_elapsed         | 467        |\n",
      "|    total_timesteps      | 309248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01441998 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.89      |\n",
      "|    explained_variance   | 0.0116     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 137        |\n",
      "|    n_updates            | 1500       |\n",
      "|    policy_gradient_loss | 0.000947   |\n",
      "|    std                  | 0.635      |\n",
      "|    value_loss           | 337        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=85.20 +/- 31.49\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 85.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 310000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009430334 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.0557      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 173         |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 0.633       |\n",
      "|    value_loss           | 307         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 3.96     |\n",
      "| time/              |          |\n",
      "|    fps             | 661      |\n",
      "|    iterations      | 152      |\n",
      "|    time_elapsed    | 470      |\n",
      "|    total_timesteps | 311296   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 29.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 661         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 473         |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009759013 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.0858      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.7        |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    std                  | 0.633       |\n",
      "|    value_loss           | 186         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 40.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 661         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 476         |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030904112 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | -0.0294     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | 0.00462     |\n",
      "|    std                  | 0.634       |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 44.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 661         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 479         |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027143035 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | -0.0146     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 62.3        |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | 0.0114      |\n",
      "|    std                  | 0.631       |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 49          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 662         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 482         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024026297 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | -0.00394    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.5        |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    std                  | 0.626       |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=166.80 +/- 10.48\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 167         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 320000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020246817 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | -0.0981     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.7        |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | 0.00288     |\n",
      "|    std                  | 0.624       |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 56.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 662      |\n",
      "|    iterations      | 157      |\n",
      "|    time_elapsed    | 485      |\n",
      "|    total_timesteps | 321536   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 61.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 662         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 488         |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029281747 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | -0.00357    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91.7        |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | 0.0255      |\n",
      "|    std                  | 0.621       |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 65.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 662         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 491         |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010223543 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | -0.00165    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 78.3        |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    std                  | 0.616       |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 67.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 662         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013223207 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.0523      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    std                  | 0.616       |\n",
      "|    value_loss           | 231         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 73.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 662         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 497         |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006019853 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | -0.0892     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.000825   |\n",
      "|    std                  | 0.614       |\n",
      "|    value_loss           | 237         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=166.00 +/- 7.69\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 166         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 330000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017275797 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.00366     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | 0.0012      |\n",
      "|    std                  | 0.61        |\n",
      "|    value_loss           | 255         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 82.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 663      |\n",
      "|    iterations      | 162      |\n",
      "|    time_elapsed    | 500      |\n",
      "|    total_timesteps | 331776   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 76.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 662         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 503         |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008401459 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.00291     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | 0.0039      |\n",
      "|    std                  | 0.612       |\n",
      "|    value_loss           | 293         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 78.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 662         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 506         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011483524 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | -0.0369     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 221         |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | 0.00383     |\n",
      "|    std                  | 0.612       |\n",
      "|    value_loss           | 323         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 75.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 661         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 510         |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028932054 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.00491     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | 0.00802     |\n",
      "|    std                  | 0.609       |\n",
      "|    value_loss           | 259         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 83.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 661         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 514         |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008836333 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.00492     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | 0.0235      |\n",
      "|    std                  | 0.61        |\n",
      "|    value_loss           | 307         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=89.60 +/- 24.83\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 89.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 340000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028609466 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.00567     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | 0.0217      |\n",
      "|    std                  | 0.607       |\n",
      "|    value_loss           | 297         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 75.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 660      |\n",
      "|    iterations      | 167      |\n",
      "|    time_elapsed    | 517      |\n",
      "|    total_timesteps | 342016   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 71.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 660         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 520         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011018069 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0.00828     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | 0.00867     |\n",
      "|    std                  | 0.608       |\n",
      "|    value_loss           | 294         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 69           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 660          |\n",
      "|    iterations           | 169          |\n",
      "|    time_elapsed         | 524          |\n",
      "|    total_timesteps      | 346112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075616795 |\n",
      "|    clip_fraction        | 0.302        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0.0186       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 97.4         |\n",
      "|    n_updates            | 1680         |\n",
      "|    policy_gradient_loss | 0.0227       |\n",
      "|    std                  | 0.607        |\n",
      "|    value_loss           | 223          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 51.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 659         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 527         |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.092480294 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.73       |\n",
      "|    explained_variance   | 0.019       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | 0.0219      |\n",
      "|    std                  | 0.605       |\n",
      "|    value_loss           | 265         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=63.20 +/- 49.62\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 63.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 350000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010484394 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.73       |\n",
      "|    explained_variance   | -0.0294     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | 0.00272     |\n",
      "|    std                  | 0.605       |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 47.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 658      |\n",
      "|    iterations      | 171      |\n",
      "|    time_elapsed    | 531      |\n",
      "|    total_timesteps | 350208   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | 46.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 658          |\n",
      "|    iterations           | 172          |\n",
      "|    time_elapsed         | 535          |\n",
      "|    total_timesteps      | 352256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077178283 |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 0.0702       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 1710         |\n",
      "|    policy_gradient_loss | -0.00945     |\n",
      "|    std                  | 0.604        |\n",
      "|    value_loss           | 193          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.4         |\n",
      "|    ep_rew_mean          | 68.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 658          |\n",
      "|    iterations           | 173          |\n",
      "|    time_elapsed         | 538          |\n",
      "|    total_timesteps      | 354304       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074767508 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.72        |\n",
      "|    explained_variance   | 0.0271       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 77.3         |\n",
      "|    n_updates            | 1720         |\n",
      "|    policy_gradient_loss | 0.000899     |\n",
      "|    std                  | 0.602        |\n",
      "|    value_loss           | 190          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 74.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 657          |\n",
      "|    iterations           | 174          |\n",
      "|    time_elapsed         | 541          |\n",
      "|    total_timesteps      | 356352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063506695 |\n",
      "|    clip_fraction        | 0.201        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.71        |\n",
      "|    explained_variance   | 0.00625      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 129          |\n",
      "|    n_updates            | 1730         |\n",
      "|    policy_gradient_loss | 0.000593     |\n",
      "|    std                  | 0.599        |\n",
      "|    value_loss           | 228          |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 60        |\n",
      "|    ep_rew_mean          | 64.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 657       |\n",
      "|    iterations           | 175       |\n",
      "|    time_elapsed         | 545       |\n",
      "|    total_timesteps      | 358400    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0523716 |\n",
      "|    clip_fraction        | 0.208     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.68     |\n",
      "|    explained_variance   | 0.014     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 114       |\n",
      "|    n_updates            | 1740      |\n",
      "|    policy_gradient_loss | 0.00652   |\n",
      "|    std                  | 0.592     |\n",
      "|    value_loss           | 216       |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=134.00 +/- 34.57\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 134         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 360000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042297035 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.66       |\n",
      "|    explained_variance   | -0.0214     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | 0.0244      |\n",
      "|    std                  | 0.592       |\n",
      "|    value_loss           | 256         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 67.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 656      |\n",
      "|    iterations      | 176      |\n",
      "|    time_elapsed    | 548      |\n",
      "|    total_timesteps | 360448   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 65.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 552         |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050831527 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.66       |\n",
      "|    explained_variance   | 0.0215      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | 0.0163      |\n",
      "|    std                  | 0.593       |\n",
      "|    value_loss           | 230         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 76.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 555         |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044312738 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.66       |\n",
      "|    explained_variance   | -0.0316     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | 0.0173      |\n",
      "|    std                  | 0.592       |\n",
      "|    value_loss           | 293         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 71.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 366592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044092104 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | -0.0136     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | 0.0221      |\n",
      "|    std                  | 0.589       |\n",
      "|    value_loss           | 266         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 69.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 561         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022126365 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.0147      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | 0.00741     |\n",
      "|    std                  | 0.583       |\n",
      "|    value_loss           | 267         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=91.20 +/- 39.69\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 91.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 370000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011066465 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.0437      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 169         |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | 0.00689     |\n",
      "|    std                  | 0.579       |\n",
      "|    value_loss           | 273         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 66.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 655      |\n",
      "|    iterations      | 181      |\n",
      "|    time_elapsed    | 565      |\n",
      "|    total_timesteps | 370688   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 69.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 655         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 568         |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014727761 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.0705      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | 0.000769    |\n",
      "|    std                  | 0.577       |\n",
      "|    value_loss           | 276         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 80.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 655         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 571         |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016721407 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.56       |\n",
      "|    explained_variance   | 0.0639      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | 0.00245     |\n",
      "|    std                  | 0.573       |\n",
      "|    value_loss           | 259         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 89.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 655         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 574         |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006100701 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.55       |\n",
      "|    explained_variance   | -0.0106     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | 0.00302     |\n",
      "|    std                  | 0.571       |\n",
      "|    value_loss           | 291         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | 89.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 655        |\n",
      "|    iterations           | 185        |\n",
      "|    time_elapsed         | 577        |\n",
      "|    total_timesteps      | 378880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01912899 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.53      |\n",
      "|    explained_variance   | -0.00107   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 156        |\n",
      "|    n_updates            | 1840       |\n",
      "|    policy_gradient_loss | 0.0088     |\n",
      "|    std                  | 0.568      |\n",
      "|    value_loss           | 330        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=164.40 +/- 8.62\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 164         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 380000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022984207 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | -0.0262     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 201         |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | 0.0169      |\n",
      "|    std                  | 0.568       |\n",
      "|    value_loss           | 351         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 88.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 655      |\n",
      "|    iterations      | 186      |\n",
      "|    time_elapsed    | 580      |\n",
      "|    total_timesteps | 380928   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 85.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 583         |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020997081 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | -0.034      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | 0.0535      |\n",
      "|    std                  | 0.568       |\n",
      "|    value_loss           | 351         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 57.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 586         |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044561677 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.51       |\n",
      "|    explained_variance   | 0.0104      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 167         |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | 0.0181      |\n",
      "|    std                  | 0.563       |\n",
      "|    value_loss           | 348         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 42          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 589         |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010894356 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.51       |\n",
      "|    explained_variance   | -0.103      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00109    |\n",
      "|    std                  | 0.566       |\n",
      "|    value_loss           | 277         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 36.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 592         |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011300779 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.52       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 0.565       |\n",
      "|    value_loss           | 227         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=152.80 +/- 15.37\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 153         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 390000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011027422 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.51       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    std                  | 0.564       |\n",
      "|    value_loss           | 222         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 67.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 656      |\n",
      "|    iterations      | 191      |\n",
      "|    time_elapsed    | 595      |\n",
      "|    total_timesteps | 391168   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 83.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 657         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008857602 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.5        |\n",
      "|    explained_variance   | 0.0307      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | 0.00134     |\n",
      "|    std                  | 0.563       |\n",
      "|    value_loss           | 267         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 90.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 657         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 601         |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015799502 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.5        |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | 0.0379      |\n",
      "|    std                  | 0.562       |\n",
      "|    value_loss           | 327         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 89          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 657         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 604         |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011252331 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.51       |\n",
      "|    explained_variance   | 0.0164      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | 0.00366     |\n",
      "|    std                  | 0.567       |\n",
      "|    value_loss           | 284         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 82.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 657         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 607         |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058974516 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.0409      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 223         |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | 0.0146      |\n",
      "|    std                  | 0.569       |\n",
      "|    value_loss           | 340         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=161.20 +/- 6.01\n",
      "Episode length: 60.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 60          |\n",
      "|    mean_reward          | 161         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 400000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014318872 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.0675      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | 0.0371      |\n",
      "|    std                  | 0.569       |\n",
      "|    value_loss           | 310         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.4     |\n",
      "|    ep_rew_mean     | 79.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 657      |\n",
      "|    iterations      | 196      |\n",
      "|    time_elapsed    | 610      |\n",
      "|    total_timesteps | 401408   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7ff5fa83dfd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stop_callback = StopTrainingOnRewardThreshold(60, 1)\n",
    "eval_callback = EvalCallback(env, eval_freq=10000, verbose=1, best_model_save_path=save_path)\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=400000, callback=eval_callback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved Models', 'PPO_model2')\n",
    "model.save(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "load_path = os.path.join('Training', 'Saved Models', 'PPO_model2')\n",
    "model = PPO.load(load_path, env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112.92, 48.61639229724887)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:120\n",
      "Episode:2 Score:60\n",
      "Episode:3 Score:30\n",
      "Episode:4 Score:128\n",
      "Episode:5 Score:78\n",
      "Episode:6 Score:6\n",
      "Episode:7 Score:38\n",
      "Episode:8 Score:56\n",
      "Episode:9 Score:104\n",
      "Episode:10 Score:86\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca9f952ef321d99a2ab24cb17ecd9558e5828ac6a303314df963ea7fdd58e81b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('deep-RL-pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
